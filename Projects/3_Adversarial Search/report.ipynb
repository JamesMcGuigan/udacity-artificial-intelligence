{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Build a Game Playing Agent - Knights Isolation\n",
    "## James McGuigan\n",
    "\n",
    "# Unit Tests\n",
    "\n",
    "```\n",
    "$ python3 -m unittest -v\n",
    "\n",
    "test_get_action_midgame (tests.test_my_custom_player.CustomPlayerGetActionTest)\n",
    "get_action() calls self.queue.put() before timeout in a game in progress ... ok\n",
    "test_get_action_player1 (tests.test_my_custom_player.CustomPlayerGetActionTest)\n",
    "get_action() calls self.queue.put() before timeout on an empty board ... ok\n",
    "test_get_action_player2 (tests.test_my_custom_player.CustomPlayerGetActionTest)\n",
    "get_action() calls self.queue.put() before timeout as player 2 ... ok\n",
    "test_get_action_terminal (tests.test_my_custom_player.CustomPlayerGetActionTest)\n",
    "get_action() calls self.queue.put() before timeout when the game is over ... ok\n",
    "test_custom_player (tests.test_my_custom_player.CustomPlayerPlayTest)\n",
    "CustomPlayer successfully completes a game against itself ... ok\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "Ran 5 tests in 22.290s\n",
    "\n",
    "OK\n",
    "```\n",
    "\n",
    "# Advanced Heuristic\n",
    "\n",
    "Code:\n",
    "```\n",
    "class CustomPlayer(BasePlayer):\n",
    "    heuristic_fn         = 'heuristic_area'  # or 'heuristic_liberties'\n",
    "    heuristic_area_depth = 4\n",
    "    heuristic_area_max   = len(Action) * 3\n",
    "\n",
    "    @staticmethod\n",
    "    @lru_cache(None, typed=True)\n",
    "    def liberties( state, cell ):\n",
    "        \"\"\"add a @lru_cache around this function\"\"\"\n",
    "        return state.liberties(cell)\n",
    "\n",
    "    @classmethod\n",
    "    @lru_cache(None, typed=True)\n",
    "    def heuristic_area( cls, state, player_id):\n",
    "        own_loc = state.locs[player_id]\n",
    "        opp_loc = state.locs[1 - player_id]\n",
    "        own_area = cls.count_area_liberties(state, own_loc)\n",
    "        opp_area = cls.count_area_liberties(state, opp_loc)\n",
    "        return own_area - opp_area\n",
    "\n",
    "    @classmethod\n",
    "    @lru_cache(None, typed=True)  # depth > 1 exceeds 150ms timeout (without caching)\n",
    "    def count_area_liberties( cls, state, start_loc ):\n",
    "        depth     = cls.heuristic_area_depth\n",
    "        max_area  = cls.heuristic_area_max\n",
    "\n",
    "        area      = set()\n",
    "        frontier  = { start_loc }\n",
    "        seen      = set()\n",
    "        while len(frontier) and len(area) < max_area and depth > 0:\n",
    "            seen     |= frontier\n",
    "            frontier |= set(chain(*[ cls.liberties(state, cell) for cell in frontier ]))\n",
    "            area     |= frontier\n",
    "            frontier -= seen\n",
    "            depth    -= 1\n",
    "        return len(area)\n",
    "```\n",
    "\n",
    "> What features of the game does your heuristic incorporate, and why do you think those features matter in evaluating states during search?\n",
    "\n",
    "The main analogy is with the game of Go. The goal is to surround your opponent and capture a larger territory.\n",
    "\n",
    "Recursively computing liberties several moves ahead shows the area of the board that the opponent\n",
    "could potentially escape to.\n",
    "\n",
    "At `depth=1` this `heuristic_area()` is equivalent to `#my_moves - #opponent_moves`\n",
    "\n",
    "Early in the game the opponent effectively has access to the entire board, making this heuristic ineffective,\n",
    "hence `max_area` is used in addition to depth to shortcircuit the computational cost of\n",
    "expanding breadth-first search to all possible future moves on a mostly empty board when neither side is trapped.\n",
    "\n",
    "This heuristic is endgame focused. It solves the simplified subproblem of local search without an adversary,\n",
    "and provides an upper-bound estimate for the difference in maximum number of total moves each player has remaining.\n",
    "It reaches maximum value for moves that trap a player within a self-contained section whilst leaving\n",
    "the other a means of escape. The player in the smaller territory will run out of moves first.\n",
    "\n",
    "The other major impact on the performance of this agent is the addition of alphabeta pruning\n",
    "with the aggressive use of `@classmethod @lru_cache()`.\n",
    "This avoids the computation expense of recomputing previously explored subtrees, and by caching on `@classmethod`\n",
    "parts of the cache can even be reused between runs. The net effect of this is to increase the\n",
    "maximum depth of iterative deepening before the timeout to beyond what `MinimaxPlayer(depth=3)` can compute.\n",
    "\n",
    "## Comparison with Baseline\n",
    "\n",
    "As we can see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import deque\n",
    "from isolation import Agent, DebugState, Isolation, play\n",
    "from my_custom_player import CustomPlayer\n",
    "from run_match import play_matches\n",
    "from sample_players import MinimaxPlayer, RandomPlayer\n",
    "import numpy as np\n",
    "\n",
    "class LibertiesPlayer(CustomPlayer):\n",
    "    heuristic_fn = 'heuristic_liberties'\n",
    "\n",
    "class HeuristicAreaPlayer(CustomPlayer):\n",
    "    heuristic_fn = 'heuristic_area'\n",
    "\n",
    "def run_match(agent1, agent2):\n",
    "    class Args:\n",
    "        fair_matches = True\n",
    "        rounds       = 25\n",
    "        time_limit   = 150\n",
    "        processes    = 8\n",
    "        debug        = False\n",
    "\n",
    "    agent1 = Agent(agent1, agent1.__name__)\n",
    "    agent2 = Agent(agent2, agent2.__name__)\n",
    "    wins, num_games = play_matches(agent1, agent2, Args)\n",
    "\n",
    "    print(\"{} won {:.1f}% of matches against {}\".format(\n",
    "       agent1.name, 100. * wins / num_games, agent2.name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LibertiesPlayer vs MinimaxPlayer\n",
    "- same heuristic\n",
    "- this shows the added performance effect just from using alphabeta pruning, iterative deepening and lru caching\n",
    "- 64% winrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 50 games:\n",
      "++-++++++++++++-+--+++++++++--+++++++++-++++++-++-+++-+-++-++-\n",
      "Running 50 games:\n",
      "+++++++++++++----++++-+++++++-+-+++++-+++++++++++++---+++++--+++++++\n",
      "LibertiesPlayer won 79.0% of matches against MinimaxPlayer\n"
     ]
    }
   ],
   "source": [
    "run_match(LibertiesPlayer, MinimaxPlayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### HeuristicPlayer vs MinimaxPlayer\n",
    "- comparing heuristic_area against reference implementation: `#my_moves - #opponent_moves` and `depth=3`\n",
    "- 88% winrate showing a significant improvement over LibertiesPlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 50 games:\n",
      "-++++++++++++-+++++++++++++++++++++++++++-+--++++++--+++-++\n",
      "Running 50 games:\n",
      "+++++++++++-++---+++++++++++++++++++++-++++++++++++++++++-+++++-\n",
      "HeuristicAreaPlayer won 88.0% of matches against MinimaxPlayer\n"
     ]
    }
   ],
   "source": [
    "run_match(HeuristicAreaPlayer, MinimaxPlayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HeuristicPlayer vs LibertiesPlayer\n",
    "- comparing heuristic_area against `#my_moves - #opponent_moves` but with equal iterative deepening and caching\n",
    "- hyperparameter tuning found that: `heuristic_area_depth=4` + `heuristic_area_max=8*5` provide the best performance\n",
    "- 76% winrate, shows that the heuristic contributes an equal amount to the performance optimizations alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 50 games:\n",
      "+++-+-+++---+++++-++-+++++++++++-++-+-++++-+-++++++++++-++++--++\n",
      "Running 50 games:\n",
      "-+--+-++++++-++++-++++++++++---++++++++++-+++++++++++++--+\n",
      "HeuristicAreaPlayer won 76.0% of matches against LibertiesPlayer\n"
     ]
    }
   ],
   "source": [
    "run_match(HeuristicAreaPlayer, LibertiesPlayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Depth Analysis\n",
    "> Analyze the search depth your agent achieves using your custom heuristic. Does search speed matter more or less than accuracy to the performance of your heuristic?\n",
    "\n",
    "\n",
    "Compared to MinimaxPlayer:\n",
    "- On the first turn, iterative deepening has trouble with the analysing beyond `depth=1`, so essentially makes a random move.\n",
    "- In the early game, during the first dozen turns, iterative deepening can manage `depth=3-4`\n",
    "which is competitive with MinimaxPlayer.\n",
    "- Towards the midgame, the depth slowly grows upto 8.\n",
    "- During the last few moves of the endgame, the depth can grow unbounded, essentially to the victory condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HeuristicVPlayer | depth:\n",
      "HeuristicVPlayer | depth: 1 2 3 \n",
      "HeuristicVPlayer | depth: 1 2 3 \n",
      "HeuristicVPlayer | depth: 1 2 3 \n",
      "HeuristicVPlayer | depth: 1 2 3 \n",
      "HeuristicVPlayer | depth: 1 2 3 \n",
      "HeuristicVPlayer | depth: 1 2 3 \n",
      "HeuristicVPlayer | depth: 1 2 3 \n",
      "HeuristicVPlayer | depth: 1 2 3 \n",
      "HeuristicVPlayer | depth: 1 2 3 \n",
      "HeuristicVPlayer | depth: 1 2 3 \n",
      "HeuristicVPlayer | depth: 1 2 3 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 \n",
      "HeuristicVPlayer | depth: 1 2 3 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \n",
      "--------------------------------------------------\n",
      "winner:  HeuristicVPlayer\n"
     ]
    }
   ],
   "source": [
    "class LibertiesVPlayer(CustomPlayer):\n",
    "    heuristic_fn  = 'heuristic_liberties'\n",
    "    verbose_depth = True\n",
    "class HeuristicVPlayer(CustomPlayer):\n",
    "    heuristic_fn = 'heuristic_area'\n",
    "    verbose_depth = True\n",
    "\n",
    "agents = (\n",
    "    Agent(HeuristicVPlayer,  \"HeuristicVPlayer\"),\n",
    "    Agent(MinimaxPlayer,     \"MinimaxPlayer\"),\n",
    ")\n",
    "initial_state = Isolation()\n",
    "winner, game_history, _ = play((agents, initial_state, 150, 0))\n",
    "print()\n",
    "print('-'*50)\n",
    "print('winner: ', winner.name)\n",
    "# print('game_history: ', game_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing HeuristicPlayer with LibertiesPlayer\n",
    "- LibertiesPlayer tends to do iterative deepening with a 1-3 depth lead over HeuristicPlayer\n",
    "- LibertiesPlayer's `#my_moves - #opponent_moves` heuristic is much cheaper to implement\n",
    "- HeuristicPlayer heuristic is effectively adding an extra 4 layers of hidden depth, but on a simplified subproblem\n",
    "- This accounts for HeuristicPlayer having a 76% winrate vs LibertiesPlayer\n",
    "- Performance optimization is still of utmost importance with a 150ms timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HeuristicVPlayer | depth:\n",
      "LibertiesVPlayer | depth: 1 2 \n",
      "HeuristicVPlayer | depth: 1 2 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 \n",
      "HeuristicVPlayer | depth: 1 2 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 \n",
      "HeuristicVPlayer | depth: 1 2 3 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 7 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 \n",
      "HeuristicVPlayer | depth: 1 2 3 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 \n",
      "HeuristicVPlayer | depth: 1 2 3 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 \n",
      "HeuristicVPlayer | depth: 1 2 3 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 \n",
      "HeuristicVPlayer | depth: 1 2 3 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 7 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 \n",
      "HeuristicVPlayer | depth: 1 2 3 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 7 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 7 8 9 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \n",
      "HeuristicVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \n",
      "LibertiesVPlayer | depth: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \n",
      "--------------------------------------------------\n",
      "winner:  HeuristicVPlayer\n"
     ]
    }
   ],
   "source": [
    "agents = (\n",
    "    Agent(HeuristicVPlayer,  \"HeuristicVPlayer\"),\n",
    "    Agent(LibertiesVPlayer,  \"LibertiesVPlayer\"),\n",
    ")\n",
    "initial_state = Isolation()\n",
    "winner, game_history, _ = play((agents, initial_state, 150, 0))\n",
    "print()\n",
    "print('-'*50)\n",
    "print('winner: ', winner.name)\n",
    "# print('game_history: ', game_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}